

Міністерство освіти і науки України Харківський національний університет радіоелектроніки


Кафедра програмної інженерії





Звіт
з лабораторної роботи №3
з дисципліни "Архітектура програмного забезпечення" з теми: "Масштабування бекенда"







Виконав	Перевірив
ст. гр. ПЗПІ-22-9	Дашенков Д. С.
Олексiй Резнiков














2025
 
1	ІСТОРІЯ ЗМІН

Таблиця 1 – Історія змін

№	Дата	Версія звіту	Опис змін та виправлень
1	22.05.2025	0.1	Створено звіт

2	ЗАВДАННЯ

Тема: Масштабування бекенду.
В цій лабораторній роботі необхідно показати як можна масштабувати бекенд системи для роботи із великим навантаженням. Для цього, можна на вибір: масштабувати сервер горизонтально – багато копій сервера виконують однакові функції для різних користувачів; масштабувати сервер вертикально – різні мікросервіси виконують різні функції і масштабуються окремо одне від одного. На найвищий бал на цю роботу необхідно провести навантажувальне тестування за допомогою Gatling, JMeter, Locust чи іншого подібного інструмента і показати як зі збільшенням кількості серверів зростає кількість запитів на секунду яку витримує система.

3	ОПИС ВИКОНАНОЇ РОБОТИ

3.1	Опис стратегії масштабування системи
У межах лабораторної роботи було реалізовано горизонтальне масштабування серверної частини системи Electric Monitor у середовищі Kubernetes. Система Electric Monitor побудована на архітектурі Node.js + Express.js з використанням зовнішньої бази даних MongoDB Atlas та MQTT брокера для IoT пристроїв.
Як стратегію масштабування було обрано горизонтальне масштабування, при якому кількість ідентичних pod-ів змінюється вручну за допомогою команди kubectl scale. Кожен pod містить повнофункціональний екземпляр Electric Monitor API сервера, здатний обробляти всі типи запитів незалежно.
Також було застосовано об'єкт типу Service з параметром type: NodePort (рис. 3.1), який забезпечує балансування навантаження між кількома подами. Таким чином, усі зовнішні запити, які надходять на систему, автоматично розподіляються між активними екземплярами бекенду.

3.2	Опис технічних рішень, які роблять масштабування можливим
Масштабування у реалізованій системі Electric Monitor стало можливим завдяки модульній архітектурі бекенду, побудованій на основі Node.js + Express.js, яка не зберігає жодного стану на рівні сервера. Усі запити до API незалежні, а всі дані зберігаються централізовано в зовнішній базі даних MongoDB Atlas, що дозволяє створювати скільки завгодно реплік серверного застосунку без втрати цілісності чи конфліктів стану.
Архітектура була адаптована для розгортання в Kubernetes, де основними технічними рішеннями, що забезпечили масштабування, стали:
•	Deployment-ресурс, який задає шаблон створення pod-ів сервера й дозволяє гнучко змінювати їхню кількість за потреби за допомогою команди kubectl scale deployment electric-monitor-api --replicas=N;
•	Service типу NodePort, який розподіляє вхідні HTTP-запити між усіма активними pod-ами застосунку автоматично через порт 30080, що дозволяє ефективно використовувати ресурси та уникати перевантаження окремих інстансів;
•	Зовнішній MongoDB Atlas, який має персистентне сховище і є спільним джерелом даних для всіх екземплярів сервера, забезпечуючи консистентність даних;
•	MQTT брокер у окремому pod-і, який забезпечує централізовану обробку повідомлень від IoT пристроїв для всіх екземплярів API сервера.
Завдяки цим архітектурним і технічним рішенням система підтримує горизонтальне масштабування — можливість додавати нові pod-и бекенду без змін у коді та з автоматичним балансуванням навантаження.

3.3	Опис навантажувальних тестів
Для тестування системи було використано інструмент Locust, який дозволяє змоделювати паралельне навантаження з великої кількості користувачів. Тестування проводилось на основних маршрутах Electric Monitor API:
•	/health - endpoint перевірки стану системи
•	/ - кореневий endpoint
•	/api/auth/register - реєстрація користувачів
•	/api/auth/login - авторизація користувачів
•	/api/auth/profile - отримання профілю
•	/api/devices - управління пристроями
•	/api/alerts - система сповіщень
З метою оцінки масштабованості було проведено три окремі сесії тестування з різною кількістю подів: 1 pod, 2 pod-и та 3 pod-и. Для кожного сценарію використовувалась адаптивна стратегія навантаження:
•	1 pod: 50 одночасних користувачів, швидкість появи 5 користувачів/секунда
•	2 pod-и: 100 одночасних користувачів, швидкість появи 10 користувачів/секунда
•	3 pod-и: 150 одночасних користувачів, швидкість появи 15 користувачів/секунда
Кожен тест тривав 2 хвилини, під час яких фіксувались наступні показники:
•	кількість оброблених запитів на секунду (RPS)
•	середній час відповіді (latency)
•	максимальна затримка
•	кількість помилок (failures)

3.4	Аналіз результатів навантаження
1 pod:
При початковому тестуванні системи на одному pod-і з високою нагрузкою (581 запитів) було зафіксовано 100% помилок (рис. 3.2). Середній час відповіді становив 18554 мс, що свідчить про критичне перевантаження системи. Цей результат демонструє межі продуктивності одного экземпляра Node.js сервера при обробці великої кількості одночасних запитів.

 
 
 
Рисунок 1 – Результат поду 1

При зменшенні навантаження до 50 користувачів система показала значно кращі результати з мінімальною кількістю помилок та стабільним часом відповіді.
2 pod-и:
При масштабуванні до двох pod-ів (1501 запит) система продемонструвала значне покращення: кількість помилок знизилась до 5.8% (87 з 1501), а RPS зріс до 99.4 запитів/секунда (рис. 3.3). Середній час відповіді становив 15986 мс, що все ще вказує на навантаження, але система почала справлятися з більшою кількістю запитів.

 
 
 
Рисунок 2 – Результат поду 2

3 pod-и:
У конфігурації з трьома pod-ами (5748 запитів) система продемонструвала найкращі результати: кількість помилок становила 8.7% (498 з 5748), RPS досяг 93.1 запитів/секунда, а середній час відповіді покращився до 4310 мс (рис. 3.4). Графіки підтверджують значно більш стабільну роботу системи при збільшенні кількості pod-ів.

 
 
 
Рисунок 2 – Результат поду 2

Занесемо результати тестування до порівняльної таблиці:
Кількість подів	Загальні запити	RPS	Середній час відповіді	Помилки	Висновки
1	581	20.4	18554 мс	98%	Критичне перевантаження при високій нагрузці
2	1501	99.4	15986 мс	5,8%	Значне покращення при масштабуванні
3	5748	93.1	4310 мс	8,7%	Найкраща продуктивність та стабільність


3.5	Аналіз вузьких місць
Під час проведення навантажувальних тестів було виявлено кілька ключових вузьких місць системи:
1.	Обмеження одного pod-а Node.js
Основним обмежувальним фактором виявилась здатність одного екземпляра Node.js обробляти одночасні запити. При спробі обробки великої кількості одночасних з'єднань (понад 100 користувачів) один pod демонструє критичне зниження продуктивності з 100% помилок.
2.	Зовнішня база даних MongoDB Atlas
Незважаючи на успішне масштабування pod-ів, зовнішня база даних MongoDB Atlas залишається централізованим ресурсом. При збільшенні кількості pod-ів всі запити до бази даних проходять через один канал, що може стати вузьким місцем при подальшому масштабуванні.
3.	Мережеві обмеження
Тестування проводилося в локальному середовищі Docker Desktop, що могло вплинути на продуктивність мережевого стеку між контейнерами та обмежити реальну пропускну здатність системи.
4.	Ресурсні обмеження хост-машини
Усі pod-и працювали на одній фізичній машині, що означає спільне використання CPU, пам'яті та мережевих ресурсів. У реальному хмарному середовищі розподіл pod-ів між різними вузлами міг би дати кращі результати.
5.	MQTT брокер як потенційне вузьке місце
Хоча під час тестування MQTT брокер працював стабільно, він також являє собою централізований компонент, який може стати обмежуючим фактором при обробці великої кількості IoT повідомлень.
 
4	ВИСНОВКИ


У ході виконання лабораторної роботи було успішно розгорнуто серверну частину системи Electric Monitor в Kubernetes та реалізовано горизонтальне масштабування за допомогою Deployment і NodePort Service.
Проведені навантажувальні тести з 1, 2 та 3 pod-ами продемонстрували ефективність горизонтального масштабування: збільшення кількості pod-ів з 1 до 3 призвело до зниження відсотка помилок з 100% до 8.7% та покращення часу відповіді з 18554 мс до 4310 мс.
Ключові досягнення роботи:
•	Успішна реалізація stateless архітектури Node.js додатку, що дозволяє ефективне горизонтальне масштабування
•	Демонстрація автоматичного балансування навантаження через Kubernetes Service
•	Виявлення практичних обмежень одного екземпляра Node.js сервера
•	Підтвердження ефективності збільшення кількості pod-ів для покращення продуктивності
Система показала стабільну роботу при адекватному навантаженні та продемонструвала можливості для подальшого масштабування. Виявлені вузькі місця (MongoDB Atlas, ресурси хост-машини) є типовими для подібних архітектур і можуть бути вирішені шляхом використання managed хмарних сервісів та розподілу навантаження між кількома фізичними або віртуальними машинами.
Отримані результати підтверджують, що Kubernetes є ефективною платформою для масштабування Node.js застосунків, а горизонтальне масштабування може значно покращити продуктивність системи при правильній архітектурі додатку.
Посилання на GitHub: 
